# LLM量化的遗忘性

**什么是大型语言模型 (LLM)？**

大型语言模型（LLM）是训练在海量文本数据上的先进机器学习模型，能够理解和生成类似人类语言的内容。这些模型，如 GPT-4 和 Claude，基于 Transformer 架构，使它们能够高效处理大规模文本序列中的上下文。LLM 在文本生成、问答、摘要和翻译等任务中表现出色。然而，它们的训练过程也会无意中吸收敏感信息或偏见，从而引发关于其使用的伦理和法律问题。

----------

**什么是机器遗忘（Machine Unlearning）？**

机器遗忘指的是在不重新训练整个模型的情况下，选择性地移除已训练模型中的特定知识或数据模式。这通常是为了符合 GDPR 的“被遗忘权”等隐私法规，或解决涉及偏见或有害内容的伦理问题。遗忘的目标是确保模型“忘记”特定知识，同时仍然能有效执行其他任务。常见的遗忘方法包括 *梯度上升（Gradient Ascent, GA）* 和 *负偏好优化（Negative Preference Optimization, NPO）*。

对于 LLM 来说，遗忘是一项特别具有挑战性的任务，因为它们的结构复杂且参数空间庞大。在确保彻底移除特定信息的同时保持模型整体功能，往往需要精细的更新、小学习率和效用约束。

----------

**什么是量化（Quantization）？**

量化是一种压缩技术，通过将模型的权重和激活值（通常以浮点数表示）降低到 8 位或 4 位整数等低位宽格式，从而减少模型的大小和推理延迟，使其适用于计算资源有限的边缘设备。

量化可以在训练过程中或训练后应用：
- *后训练量化（Post-Training Quantization, PTQ）*：模型训练完成后进行量化，可选择性地进行校准以最小化精度损失。
- *量化感知训练（Quantization-Aware Training, QAT）*：在训练过程中模拟量化影响，以提高量化后的性能。

设一组权重 $w$，其原始线性运算表示为：

$$
y = wx
$$

在量化版本中，该公式变为：

$$
y = Q(w)x
$$

其中 $Q(\cdot)$ 是量化函数，具体定义如下：

$$
Q(w) = \Delta \cdot \text{Round}\left(\frac{w}{\Delta}\right)
$$

量化尺度因子 $\Delta$ 计算如下：

$$
\Delta = \frac{\max(|w|)}{2^{N-1}}
$$

其中：
- $N$ 为量化位数。
- $\Delta$ 为量化步长，基于 $w$ 的绝对最大值计算。

该公式确保权重被缩放并舍入到由量化精度 $N$ 定义的离散级别。

----------

### 4 位量化可能会使现有的机器遗忘技术失效！

![图 1](https://scsai.github.io/posts/quant_unlearn/figure1.png "图 1")

在使用机器遗忘从 LLM 中移除特定知识（如版权内容或私人数据）时，我们可能认为该过程是有效的。然而，我们发现对“已遗忘”模型应用 4 位量化后，部分或全部被遗忘的知识可能被恢复。

![图 2](https://scsai.github.io/posts/quant_unlearn/figure2.png "图 2")

我们研究了六种遗忘方法——将 *梯度上升（GA）* 或 *负偏好优化（NPO）* 与 *保留数据的梯度下降（GDR）* 或 *KL 散度最小化（KLR）* 结合。这些方法包括 *GA, GA_GDR, GA_KLR, NPO, NPO_GDR, NPO_KLR*。在全精度模型中，这些方法的遗忘效果尚可，遗忘知识的平均保留率仅为 **21%**。但在 4 位量化后，这一保留率飙升至 **83%**，意味着大部分被遗忘的知识被恢复。

----------

#### 量化精度的影响

![图 3](https://scsai.github.io/posts/quant_unlearn/figure3.png "图 3")

我们的实验表明，量化精度对遗忘效果影响显著。例如，8 位量化对遗忘的影响较小，其结果接近全精度模型。而 4 位量化则严重削弱了遗忘性能。这一现象在 **NEWS**（BBC 新闻文章）和 **BOOKS**（哈利波特系列）等基准数据集上均得到了验证。

----------

#### 量化方法的影响

使用高级 4 位量化方法，如 _GPTQ_ 和 _AWQ_，我们观察到相似的知识恢复模式。尽管进行了参数优化，但由于采用的是通用校准数据集，而非专门针对遗忘内容的数据集，这些数据集未能充分考虑遗忘过程中涉及的特定动态，导致知识恢复。

----------

### 根本原因及我们的解决方案

问题的根本原因在于，遗忘过程中由于小学习率和效用保持目标，对权重所做的修改幅度很小。而在量化时，这些微小变化容易被覆盖，使得遗忘信息得以恢复。

![图 4](https://scsai.github.io/posts/quant_unlearn/figure4.png "图 4")

为了解决这一问题，我们提出了 **SURE 框架（基于显著性的大学习率遗忘，Saliency-Based Unlearning with a Large Learning Rate）**。该框架构建模块级显著性图，以指导遗忘过程，重点关注与被遗忘数据最相关的组件，同时最大限度减少对其他功能的干扰。通过选择性地使用较大的学习率，SURE 能够防止知识在量化后被恢复。

具体而言，我们计算每个模块的显著性分数 $s_i$，该分数是遗忘损失对参数 $\theta_i$ 的梯度的聚合：

$$
s_i = \|\nabla_{\theta_i} \mathcal{L}_{\text{forget}}(\theta; D_{\text{forget}})\|_{\theta=\theta_o},
$$

其中 $\|\cdot\|$ 代表适当的范数（如矩阵的 Frobenius 范数），用于总结模块 $i$ 的梯度幅度。

然后，我们应用硬阈值操作得到模块级显著性图 $m_M$：

$$
m_M[i] = \begin{cases} 1, & \text{如果 } s_i \geq \gamma, \\ 0, & \text{否则}, \end{cases}
$$

其中 $\gamma > 0$ 为阈值。最终，我们的遗忘模型参数 $\theta_u$ 表达为：

$$
\theta_u = \theta_o + m_M \odot \Delta\theta,
$$

实验验证了 SURE 的有效性，在全精度模型上能够实现与现有方法相当的遗忘性能和效用保持。

-----
**论文:** [https://arxiv.org/pdf/2410.16454](https://arxiv.org/pdf/2410.16454)

**GitHub 仓库:** [https://github.com/zzwjames/FailureLLMUnlearning](https://github.com/zzwjames/FailureLLMUnlearning)

